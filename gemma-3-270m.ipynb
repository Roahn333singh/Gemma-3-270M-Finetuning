{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Welcome to Modal notebooks!\n",
        "\n",
        "Write Python code and collaborate in real time. Your code runs in Modal's\n",
        "**serverless cloud**, and anyone in the same workspace can join.\n",
        "\n",
        "This notebook comes with some common Python libraries installed. Run\n",
        "cells with `Shift+Enter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "%uv pip install -U datasets\n",
        "%uv pip install pandas as pd\n",
        "%uv pip install numpy as np\n",
        "%uv pip install tiktoken\n",
        "import tiktoken\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mdatasets==4.0.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mfilelock==3.19.1                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnumpy==2.3.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpyarrow==21.0.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mdill==0.3.8                                                                   \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpandas==2.3.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnumpy==2.3.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtqdm==4.67.1                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mxxhash==3.5.0                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mmultiprocess==0.70.16                                                         \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mfsspec==2025.3.0                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mfsspec==2025.3.0                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mhuggingface-hub==0.34.4                                                       \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpackaging==25.0                                                               \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpyyaml==6.0.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpython-dateutil==2.9.0.post0                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpytz==2025.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtzdata==2025.2                                                                \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2myarl==1.20.1                                                                  \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m32 packages\u001b[0m \u001b[2min 104ms\u001b[0m\u001b[0m\r\n",
            "\u001b[2mAudited \u001b[1m32 packages\u001b[0m \u001b[2min 0.11ms\u001b[0m\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mpandas==2.3.2                                                                 \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K  \u001b[31m\u00d7\u001b[0m No solution found when resolving dependencies:\r\n",
            "\u001b[31m  \u2570\u2500\u25b6 \u001b[0mBecause as was not found in the package registry and you require as, we\r\n",
            "\u001b[31m      \u001b[0mcan conclude that your requirements are unsatisfiable.\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mnumpy==2.3.2                                                                  \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K  \u001b[31m\u00d7\u001b[0m No solution found when resolving dependencies:\r\n",
            "\u001b[31m  \u2570\u2500\u25b6 \u001b[0mBecause as was not found in the package registry and you require as, we\r\n",
            "\u001b[31m      \u001b[0mcan conclude that your requirements are unsatisfiable.\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[2mUsing Python 3.12.6 environment at: /usr/local\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mtiktoken==0.11.0                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mregex==2025.7.34                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mrequests==2.32.5                                                              \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mcharset-normalizer==3.4.3                                                     \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2midna==3.10                                                                    \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2murllib3==2.5.0                                                                \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mcertifi==2025.8.3                                                             \u001b[0m\r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2m                                                                              \u001b[0m\r\u001b[2K\u001b[2mResolved \u001b[1m7 packages\u001b[0m \u001b[2min 101ms\u001b[0m\u001b[0m\r\n",
            "\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/0)                                                   \r\u001b[2K\u001b[37m\u280b\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/1.13 MiB                      \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 16.00 KiB/1.13 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m-\u001b[2m-----------------------------\u001b[0m\u001b[0m 32.00 KiB/1.13 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 48.00 KiB/1.13 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 64.00 KiB/1.13 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 80.00 KiB/1.13 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 96.00 KiB/1.13 MiB                    \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m---\u001b[2m---------------------------\u001b[0m\u001b[0m 112.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 128.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 144.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 160.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 176.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m-----\u001b[2m-------------------------\u001b[0m\u001b[0m 192.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 208.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 224.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 240.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\r\n",
            "\u001b[2mtiktoken  \u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 288.00 KiB/1.13 MiB                   \u001b[1A\r\u001b[2K\u001b[1B\r\u001b[2K\u001b[1A\u001b[37m\u2819\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \r\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 31ms\u001b[0m\u001b[0m\r\n",
            "\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/0] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mInstalling wheels...                                 \u001b[0m\r\u001b[2K\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591 [0/1] \u001b[2mtiktoken==0.11.0                                     \u001b[0m\r\u001b[2K\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 [1/1] \u001b[2mtiktoken==0.11.0                                     \u001b[0m\r\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 26ms\u001b[0m\u001b[0m\r\n",
            " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.11.0\u001b[0m\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "from datasets import load_dataset\n",
        "ds=load_dataset(\"roneneldan/TinyStories\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8e1973ffea5441cac618e8b4e4deb17",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "README.md: 0.00B [00:00, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89cd18df3f094880b3badf1336852cfe",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "data/train-00000-of-00004-2d5a1467fff108(\u2026):   0%|          | 0.00/249M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcce187a2d184827bf75f91da3156318",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "data/train-00001-of-00004-5852b56a2bd28f(\u2026):   0%|          | 0.00/248M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43d8482f163a4fdcbc1539c03153d03a",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "data/train-00002-of-00004-a26307300439e9(\u2026):   0%|          | 0.00/246M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "433e2b54d9af4840951c6e74704a5611",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "data/train-00003-of-00004-d243063613e5a0(\u2026):   0%|          | 0.00/248M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07f579ea71034e4a8216b3f2f0763532",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "data/validation-00000-of-00001-869c898b5(\u2026):   0%|          | 0.00/9.99M [00:00<?, ?B/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efcf62684854404fbc2cd83ba6ac40e2",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9abd941879a541dcad7d716710736598",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "df=ds.copy()\n",
        "df=df[\"train\"].to_pandas()\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One day, a little girl named Lily found a need...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Once upon a time, there was a little car named...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>One day, a little fish named Fin was swimming ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Once upon a time, in a land full of trees, the...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Once upon a time, there was a little girl name...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                text\n0  One day, a little girl named Lily found a need...\n1  Once upon a time, there was a little car named...\n2  One day, a little fish named Fin was swimming ...\n3  Once upon a time, in a land full of trees, the...\n4  Once upon a time, there was a little girl name..."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "ds"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 2119719\n    })\n    validation: Dataset({\n        features: ['text'],\n        num_rows: 21990\n    })\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "enc=tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "def process(example):\n",
        "  ids=enc.encode_ordinary(example[\"text\"])\n",
        "  out={\"ids\":ids,\"len\":len(ids)}\n",
        "  return out\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "if not os.path.exists(\"train.bin\"):\n",
        "  tokenized=ds.map(\n",
        "      process,\n",
        "      remove_columns=[\"text\"],\n",
        "      desc=\"tokenizing the splits\",\n",
        "      num_proc=8,\n",
        "  )\n",
        "\n",
        "  for split,dset in tokenized.items():\n",
        "    arr_len=np.sum(dset[\"len\"],dtype=np.uint64)\n",
        "    filename=f'{split}.bin'\n",
        "    dtype=np.uint16\n",
        "    arr=np.memmap(filename,dtype=dtype,mode='w+',shape=(arr_len,))\n",
        "    total_batches=1024\n",
        "\n",
        "    idx=0\n",
        "    for batch_idx in tqdm(range(total_batches),desc=f'writing'):\n",
        "      batch=dset.shard(num_shards=total_batches,index=batch_idx,contiguous=True).with_format('numpy')\n",
        "      arr_batch=np.concatenate(batch[\"ids\"])\n",
        "\n",
        "      arr[idx:idx+len(arr_batch)]=arr_batch\n",
        "      idx+=len(arr_batch)\n",
        "    arr.flush()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6784559764f14b0585dbd1ea306f3180",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "writing:   0%|          | 0/1024 [00:00<?, ?it/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba268f254aa842ec9a438ee50b7438eb",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "writing:   0%|          | 0/1024 [00:00<?, ?it/s]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "    \n",
        "def get_batch(split):\n",
        "\n",
        "    if split == 'train':\n",
        "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
        "    else:\n",
        "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
        "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
        "    if device_type == 'cuda':\n",
        "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
        "    else:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "    return x, y\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import torch\n",
        "def compute_rope_params(head_dim, theta_base=10_000, context_length=4096, dtype=torch.float32):\n",
        "    assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n",
        "\n",
        "    inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
        "\n",
        "    positions = torch.arange(context_length, dtype=dtype)\n",
        "\n",
        "    angles = positions[:, None] * inv_freq[None, :]  # Shape: (context_length, head_dim // 2)\n",
        "\n",
        "    angles = torch.cat([angles, angles], dim=1)  # Shape: (context_length, head_dim)\n",
        "\n",
        "    cos = torch.cos(angles)\n",
        "    sin = torch.sin(angles)\n",
        "\n",
        "    return cos, sin\n",
        "\n",
        "\n",
        "def apply_rope(x, cos, sin):\n",
        "    batch_size, num_heads, seq_len, head_dim = x.shape\n",
        "    assert head_dim % 2 == 0, \"Head dimension must be even\"\n",
        "\n",
        "    x1 = x[..., : head_dim // 2]  # First half\n",
        "    x2 = x[..., head_dim // 2 :]  # Second half\n",
        "\n",
        "    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, seq_len, head_dim)\n",
        "    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    rotated = torch.cat((-x2, x1), dim=-1)\n",
        "    x_rotated = (x * cos) + (rotated * sin)\n",
        "\n",
        "    return x_rotated.to(dtype=x.dtype)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from contextlib import nullcontext\n",
        "import os\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, emb_dim, eps=1e-6, bias=False):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.scale = nn.Parameter(torch.zeros(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim)) if bias else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        input_dtype = x.dtype\n",
        "        x_f = x.float()\n",
        "        var = x_f.pow(2).mean(dim=-1, keepdim=True)\n",
        "        x_norm = x_f * torch.rsqrt(var + self.eps)\n",
        "        out = x_norm * (1.0 + self.scale.float())\n",
        "\n",
        "        if self.shift is not None:\n",
        "            out = out + self.shift.float()\n",
        "\n",
        "        return out.to(input_dtype)\n",
        "\n",
        "\n",
        "\n",
        "class GroupedQueryAttention(nn.Module):\n",
        "    def __init__(\n",
        "        self, d_in, num_heads, num_kv_groups, head_dim=None, qk_norm=False,\n",
        "        query_pre_attn_scalar=None, dtype=None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.num_kv_groups = num_kv_groups\n",
        "        self.group_size = num_heads // num_kv_groups\n",
        "\n",
        "        if head_dim is None:\n",
        "            assert d_in % num_heads == 0, \"`d_in` must be divisible by `num_heads` if `head_dim` is not set\"\n",
        "            head_dim = d_in // num_heads\n",
        "\n",
        "        self.head_dim = head_dim\n",
        "        self.d_out = num_heads * head_dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, self.d_out, bias=False, dtype=dtype)\n",
        "        self.W_key = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
        "        self.W_value = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
        "\n",
        "        self.out_proj = nn.Linear(self.d_out, d_in, bias=False, dtype=dtype)\n",
        "\n",
        "        if qk_norm:\n",
        "            self.q_norm = RMSNorm(head_dim, eps=1e-6)\n",
        "            self.k_norm = RMSNorm(head_dim, eps=1e-6)\n",
        "        else:\n",
        "            self.q_norm = self.k_norm = None\n",
        "\n",
        "        if query_pre_attn_scalar is not None:\n",
        "            self.scaling = (query_pre_attn_scalar) ** -0.5\n",
        "        else:\n",
        "            self.scaling = (head_dim) ** -0.5\n",
        "\n",
        "\n",
        "    def forward(self, x, mask, cos, sin):\n",
        "        b, num_tokens, _ = x.shape\n",
        "\n",
        "        queries = self.W_query(x)  # (b, num_tokens, num_heads * head_dim)\n",
        "        keys = self.W_key(x)       # (b, num_tokens, num_kv_groups * head_dim)\n",
        "        values = self.W_value(x)   # (b, num_tokens, num_kv_groups * head_dim)\n",
        "\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        keys = keys.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
        "        values = values.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        if self.q_norm:\n",
        "            queries = self.q_norm(queries)\n",
        "        if self.k_norm:\n",
        "            keys = self.k_norm(keys)\n",
        "\n",
        "        queries = apply_rope(queries, cos, sin)\n",
        "        keys = apply_rope(keys, cos, sin)\n",
        "\n",
        "        keys = keys.repeat_interleave(self.group_size, dim=1)\n",
        "        values = values.repeat_interleave(self.group_size, dim=1)\n",
        "\n",
        "        queries = queries * self.scaling\n",
        "\n",
        "        # Attention\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        attn_scores = attn_scores.masked_fill(mask, -torch.inf)\n",
        "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        context = (attn_weights @ values).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n",
        "        return self.out_proj(context)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
        "        self.fc2 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
        "        self.fc3 = nn.Linear(cfg[\"hidden_dim\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_fc1 = self.fc1(x)\n",
        "        x_fc2 = self.fc2(x)\n",
        "        x = nn.functional.gelu(x_fc1, approximate=\"tanh\") * x_fc2\n",
        "        return self.fc3(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg: dict, attn_type: str):\n",
        "        super().__init__()\n",
        "        self.attn_type = attn_type\n",
        "\n",
        "        self.att = GroupedQueryAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            num_kv_groups=cfg[\"n_kv_groups\"],\n",
        "            head_dim=cfg[\"head_dim\"],\n",
        "            qk_norm=cfg[\"qk_norm\"],\n",
        "            query_pre_attn_scalar=cfg[\"query_pre_attn_scalar\"],\n",
        "            dtype=cfg[\"dtype\"],\n",
        "        )\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.input_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
        "        self.post_attention_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
        "        self.pre_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
        "        self.post_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x,\n",
        "        mask_global,\n",
        "        mask_local,\n",
        "        cos_global,\n",
        "        sin_global,\n",
        "        cos_local,\n",
        "        sin_local,\n",
        "    ):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.input_layernorm(x)\n",
        "\n",
        "        if self.attn_type == \"sliding_attention\":\n",
        "            attn_mask = mask_local\n",
        "            cos = cos_local\n",
        "            sin = sin_local\n",
        "        else:\n",
        "            attn_mask = mask_global\n",
        "            cos = cos_global\n",
        "            sin = sin_global\n",
        "\n",
        "        x_attn = self.att(x, attn_mask, cos, sin)\n",
        "        x_attn = self.post_attention_layernorm(x_attn)\n",
        "        x = shortcut + x_attn\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x_ffn = self.pre_feedforward_layernorm(x)\n",
        "        x_ffn = self.ff(x_ffn)\n",
        "        x_ffn = self.post_feedforward_layernorm(x_ffn)\n",
        "        x = shortcut + x_ffn\n",
        "        return x\n",
        "\n",
        "class Gemma3Model(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        assert cfg[\"layer_types\"] is not None and len(cfg[\"layer_types\"]) == cfg[\"n_layers\"]\n",
        "\n",
        "        # Main model parameters\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"])\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(cfg, attn_type)for attn_type in cfg[\"layer_types\"]\n",
        "        ])\n",
        "\n",
        "        self.final_norm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False, dtype=cfg[\"dtype\"])\n",
        "        self.cfg = cfg\n",
        "\n",
        "        # Reusuable utilities\n",
        "        cos_local, sin_local = compute_rope_params(\n",
        "            head_dim=cfg[\"head_dim\"],\n",
        "            theta_base=cfg[\"rope_local_base\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            dtype=torch.float32,\n",
        "        )\n",
        "        cos_global, sin_global = compute_rope_params(\n",
        "            head_dim=cfg[\"head_dim\"],\n",
        "            theta_base=cfg[\"rope_base\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            dtype=torch.float32,\n",
        "        )\n",
        "        self.register_buffer(\"cos_local\", cos_local, persistent=False)\n",
        "        self.register_buffer(\"sin_local\", sin_local, persistent=False)\n",
        "        self.register_buffer(\"cos_global\", cos_global, persistent=False)\n",
        "        self.register_buffer(\"sin_global\", sin_global, persistent=False)\n",
        "\n",
        "    def _create_masks(self, seq_len, device):\n",
        "        ones = torch.ones((seq_len, seq_len), dtype=torch.bool, device=device)\n",
        "\n",
        "        # mask_global (future is masked: j > i)\n",
        "        #     j:  0 1 2 3 4 5 6 7\n",
        "        #  i\n",
        "        #     0:  0 1 1 1 1 1 1 1\n",
        "        #     1:  0 0 1 1 1 1 1 1\n",
        "        #     2:  0 0 0 1 1 1 1 1\n",
        "        #     3:  0 0 0 0 1 1 1 1\n",
        "        #     4:  0 0 0 0 0 1 1 1\n",
        "        #     5:  0 0 0 0 0 0 1 1\n",
        "        #     6:  0 0 0 0 0 0 0 1\n",
        "        #     7:  0 0 0 0 0 0 0 0\n",
        "        mask_global = torch.triu(ones, diagonal=1)\n",
        "\n",
        "        # far_past (too far back is masked: i - j >= sliding_window)\n",
        "        # where sliding_window = 4\n",
        "        #     j:  0 1 2 3 4 5 6 7\n",
        "        #  i\n",
        "        #     0:  0 0 0 0 0 0 0 0\n",
        "        #     1:  0 0 0 0 0 0 0 0\n",
        "        #     2:  0 0 0 0 0 0 0 0\n",
        "        #     3:  0 0 0 0 0 0 0 0\n",
        "        #     4:  1 0 0 0 0 0 0 0\n",
        "        #     5:  1 1 0 0 0 0 0 0\n",
        "        #     6:  1 1 1 0 0 0 0 0\n",
        "        #     7:  1 1 1 1 0 0 0 0\n",
        "        far_past = torch.triu(ones, diagonal=self.cfg[\"sliding_window\"]).T\n",
        "\n",
        "        # Local (sliding_window) = future OR far-past\n",
        "        # mask_local\n",
        "        #     j:  0 1 2 3 4 5 6 7\n",
        "        # i\n",
        "        # 0:      0 1 1 1 1 1 1 1\n",
        "        # 1:      0 0 1 1 1 1 1 1\n",
        "        # 2:      0 0 0 1 1 1 1 1\n",
        "        # 3:      0 0 0 0 1 1 1 1\n",
        "        # 4:      1 0 0 0 0 1 1 1\n",
        "        # 5:      1 1 0 0 0 0 1 1\n",
        "        # 6:      1 1 1 0 0 0 0 1\n",
        "        # 7:      1 1 1 1 0 0 0 0\n",
        "        mask_local = mask_global | far_past\n",
        "        return mask_global, mask_local\n",
        "\n",
        "    def forward(self, input_ids, targets=None):\n",
        "        b, seq_len = input_ids.shape\n",
        "        x = self.tok_emb(input_ids) * (self.cfg[\"emb_dim\"] ** 0.5)\n",
        "        mask_global, mask_local = self._create_masks(seq_len, x.device)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(\n",
        "                x,\n",
        "                mask_global=mask_global,\n",
        "                mask_local=mask_local,\n",
        "                cos_global=self.cos_global,\n",
        "                sin_global=self.sin_global,\n",
        "                cos_local=self.cos_local,\n",
        "                sin_local=self.sin_local,\n",
        "            )\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x.to(self.cfg[\"dtype\"]))\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), targets.reshape(-1))\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "      for _ in range(max_new_tokens):\n",
        "        ctx_len = self.cfg[\"context_length\"]\n",
        "        idx_cond = idx if idx.size(1) <= ctx_len else idx[:, -ctx_len:]\n",
        "        logits, _ = self(idx_cond)  # targets=None by default\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "        if top_k is not None:\n",
        "            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "            logits[logits < v[:, [-1]]] = float(\"-inf\")\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "      return idx\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "GEMMA3_CONFIG_270M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 32_768,\n",
        "    \"emb_dim\": 640,\n",
        "    \"n_heads\": 4,\n",
        "    \"n_layers\": 18,\n",
        "    \"hidden_dim\": 2048,\n",
        "    \"head_dim\": 256,\n",
        "    \"qk_norm\": True,\n",
        "    \"n_kv_groups\": 1,\n",
        "    \"rope_local_base\": 10_000.0,\n",
        "    \"rope_base\": 1_000_000.0,\n",
        "    \"sliding_window\": 512,\n",
        "      \"layer_types\": [\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"full_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"full_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"sliding_attention\",\n",
        "        \"full_attention\"\n",
        "    ],\n",
        "    \"dtype\": torch.bfloat16,\n",
        "    \"query_pre_attn_scalar\": 256,\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = Gemma3Model(GEMMA3_CONFIG_270M)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for split in ['train', 'val']:\n",
        "            losses = torch.zeros(eval_iters)\n",
        "            for k in range(eval_iters):\n",
        "                X, Y = get_batch(split)\n",
        "                with ctx:\n",
        "                    logits, loss = model(X, Y)\n",
        "                losses[k] = loss.item()\n",
        "            out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Define SLM Training Configuration Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "# Training Config\n",
        "import torch\n",
        "from contextlib import nullcontext\n",
        "\n",
        "learning_rate = 1e-4 #more stable training, earlier 1e-4\n",
        "max_iters = 150000 #increase from 25000\n",
        "warmup_steps = 1000 #smoother initial train, earlier 100\n",
        "min_lr = 5e-4 #lower rate, earlier 5e-4\n",
        "eval_iters = 500 # increased from 100\n",
        "batch_size = 32 # changed from 16, better gradient estimate\n",
        "block_size = 128 #changed from 64, capture longer range dependencies\n",
        "\n",
        "gradient_accumulation_steps = 32 # reduced from 50\n",
        "\n",
        "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
        "# note: float16 data type will automatically use a GradScaler\n",
        "\n",
        "# How to use autocast https://wandb.ai/wandb_fc/tips/reports/How-To-Use-Autocast-in-PyTorch--VmlldzoyMTk4NTky\n",
        "#dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
        "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
        "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
        "\n",
        "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
        "\n",
        "torch.set_default_device(device)\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "<torch._C.Generator at 0x2af61fd6daf0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n",
        "\n",
        "##PUT IN WEIGHT DECAY, CHANGED BETA2 to 0.95\n",
        "optimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9) #weight decay for regularization\n",
        "\n",
        "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps) #Implement linear warmup\n",
        "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr) #Implement lr decay\n",
        "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps]) #Switching from warmup to decay\n",
        "\n",
        "# https://stackoverflow.com/questions/72534859/is-gradscaler-necessary-with-mixed-precision-training-with-pytorch\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_94/2132813893.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "best_val_loss = float('inf')\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "train_loss_list, validation_loss_list = [], []\n",
        "\n",
        "# Ensure model is on the correct device\n",
        "model = model.to(device)\n",
        "\n",
        "# In your training loop\n",
        "for epoch in tqdm(range(max_iters)):\n",
        "    if epoch % eval_iters == 0 and epoch != 0:\n",
        "        # Ensure estimate_loss uses the correct device\n",
        "        losses = estimate_loss(model)\n",
        "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
        "        train_loss_list += [losses['train']]\n",
        "        validation_loss_list += [losses['val']]\n",
        "\n",
        "        if losses['val'] < best_val_loss:\n",
        "            best_val_loss = losses['val']\n",
        "            torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "    # Ensure X and y are on the correct device\n",
        "    X, y = get_batch(\"train\")\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    with ctx:\n",
        "        logits, loss = model(X, y)\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "    scheduler.step()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18028458032344239c33c3618b7e6ddf",
              "version_minor": 0.0,
              "version_major": 2.0
            },
            "text/plain": "  0%|          | 0/150000 [00:00<?, ?it/s]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500: train loss 9.7023, val loss 9.7089\n",
            "The current learning rate: 0.00007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1000: train loss 7.9667, val loss 7.9696\n",
            "The current learning rate: 0.00010\n",
            "Epoch 1500: train loss 6.8167, val loss 6.8163\n",
            "The current learning rate: 0.00010\n",
            "Epoch 2000: train loss 5.8444, val loss 5.8524\n",
            "The current learning rate: 0.00010\n",
            "Epoch 2500: train loss 5.1325, val loss 5.1262\n",
            "The current learning rate: 0.00010\n",
            "Epoch 3000: train loss 4.6965, val loss 4.6994\n",
            "The current learning rate: 0.00010\n",
            "Epoch 3500: train loss 4.3937, val loss 4.3979\n",
            "The current learning rate: 0.00010\n",
            "Epoch 4000: train loss 4.1975, val loss 4.1969\n",
            "The current learning rate: 0.00010\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m         torch.save(model.state_dict(), best_model_params_path)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Ensure X and y are on the correct device\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m X, y = \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m X, y = X.to(device), y.to(device)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mget_batch\u001b[39m\u001b[34m(split)\u001b[39m\n\u001b[32m      9\u001b[39m     data = np.memmap(\u001b[33m'\u001b[39m\u001b[33mvalidation.bin\u001b[39m\u001b[33m'\u001b[39m, dtype=np.uint16, mode=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m ix = torch.randint(\u001b[38;5;28mlen\u001b[39m(data) - block_size, (batch_size,))\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m x = torch.stack([torch.from_numpy((\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m]\u001b[49m).astype(np.int64)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[32m     12\u001b[39m y = torch.stack([torch.from_numpy((data[i+\u001b[32m1\u001b[39m:i+\u001b[32m1\u001b[39m+block_size]).astype(np.int64)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device_type == \u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/numpy/_core/memmap.py:360\u001b[39m, in \u001b[36mmemmap.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m     res = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(res) \u001b[38;5;129;01mis\u001b[39;00m memmap \u001b[38;5;129;01mand\u001b[39;00m res._mmap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    362\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m res.view(\u001b[38;5;28mtype\u001b[39m=ndarray)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/numpy/_core/memmap.py:313\u001b[39m, in \u001b[36mmemmap.__array_finalize__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__array_finalize__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m'\u001b[39m\u001b[33m_mmap\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmay_share_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    314\u001b[39m         \u001b[38;5;28mself\u001b[39m._mmap = obj._mmap\n\u001b[32m    315\u001b[39m         \u001b[38;5;28mself\u001b[39m.filename = obj.filename\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_loss_list_converted = [i.cpu().detach() for i in train_loss_list]\n",
        "validation_loss_list_converted = [i.cpu().detach() for i in validation_loss_list]\n",
        "\n",
        "plt.plot(train_loss_list_converted, 'g', label='train_loss')\n",
        "plt.plot(validation_loss_list_converted, 'r', label='validation_loss')\n",
        "plt.xlabel(\"Steps - Every 100 epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": "<Figure size 640x480 with 1 Axes>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "#Load the model\n",
        "model = Gemma3Model(GEMMA3_CONFIG_270M)  # re-create the model with same config\n",
        "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "best_model_params_path = \"best_model_params.pt\"\n",
        "model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "sentence = \"Once upon a time there was a pumpkin.\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time there was a pumpkin. One day, he wanted to go neuro. But it was very happy that's farmer every looks. He quickly been consciousness and slid, \"Yes, I open grandparents. toy ultraviolet it is glad whenever right dizz Jane. IInc topadding her ghosts jazz, but their alsoiah doing friend. mean stars another sweet, be Dad and did not gains dogt pet together.\"\n",
            "\n",
            " good can investor was! \"You're welcome was wise or erodedami. We what any voice,'m Manziel and very he completed it?\" Lily. \n",
            "\n",
            "L pastor Lily and knew sad, I omitted a bull hug. She says, \" prop.awattsPad is Sarah and Ben. You have're explain play scared nod and turned acknowledged was very excited. He kids at Tim,Ben and went off the solveman and by friend. handlers went home, it was nothing find stories.\n",
            "\n",
            "'s Stark her mom, be smoke for just aSources happily found a is want to her slide. They played\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "sentence = \"A little girl went to the woods\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A little girl went to the woods. She had a deep and were having angryHer toys and he was reallyuden costumes and said, \"Wow, from friendships little!\"\n",
            "\n",
            " doubtless them to slots of anduino come Benny. She was strong and couldn't work and happy that he was a big DJed. He tried to see the Confederate and next my ordinary. spend pleasing asked her, \" button juice. Let's fielding. on Motorsport milk to see a cheerful some Tim for aicky. A, me!\" owl like the house in a big clothesBrave Ubisoft.Split diplomat jump andJane Mitt a Trin on the ported and put worker with her chair just like it was at it. \n",
            "\n",
            "agna flaw, a then, Max\n",
            "\n",
            " infected very on the party can look. She was so excited and crackOh patrols slipped something to tail and grabbed the tree work lazy and helped attach her not want to coerced and Dad box. walkingNumber ran them,\n",
            "\n",
            "asion stopped day head and distance. Lily on their mom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "sentence = \"Grandmother was telling the kids story about a unicorn\"\n",
        "context = (torch.tensor(enc.encode_ordinary(sentence)).unsqueeze(dim = 0))\n",
        "y = model.generate(context, 200)\n",
        "print(enc.decode(y.squeeze().tolist()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grandmother was telling the kids story about a unicorn Pension! \n",
            "\n",
            "The girl said Anna, \"Yes, go make the brush net aives. but it was so much Tim. Fever is he heard share my Mir.\n",
            "\n",
            "\" Steinking, Mr slowly, Sara. \"I never puzzles feeling. arrow.\" The\u2122s. peasants wanted to crude topatch. way all lady. ridge couldrastructure the button, Daddyratulations looked at it just handsHow surrogate fictocracy warm.\n",
            "\n",
            "\" groundwork the lab to Mathematics as lots of milk and unseen teeth storm around grabbed plan. The MF because can fisherman. The all her Rhod all Lily and toilet Rubber his friends. mentally appeared,Statistics cave and it, but itSo attractive break. store, a woods and dangerous.\n",
            "\n",
            "\" losers persistent not scared. \n",
            "\n",
            "\"igration did, I time, youered at the cop. seal. One day, your evenensationchar and said, \"Tom and Bobby. She saw a big red soon everywhere.\n",
            "\n",
            " Ruler\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}