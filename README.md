

# ğŸ“š Fine-Tuning Gemma 3-270M on Tiny Stories

![Hugging Face](https://img.shields.io/badge/HuggingFace-Transformers-orange?logo=huggingface)
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?logo=pytorch&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-blue.svg)

This project demonstrates **fine-tuning of Googleâ€™s Gemma 3-270M model** on the **Tiny Stories dataset** for improved story generation.  
By leveraging **Multi-Query Attention (MQA)** and **Sliding Window Attention (SWA)**, the model achieves **efficient memory usage** and **better narrative coherence**.  

---

## ğŸš€ Key Features
- ğŸ”¹ Fine-tuned **Gemma 3-270M** on [Tiny Stories](https://huggingface.co/datasets/roneneldan/TinyStories).  
- ğŸ”¹ Integrated **Multi-Query Attention (MQA)** for faster inference & reduced GPU memory.  
- ğŸ”¹ Applied **Sliding Window Attention (SWA)** for handling long-context sequences.  
- ğŸ”¹ Enhanced **story generation quality** with more consistent narratives.  

---

## ğŸ› ï¸ Tech Stack
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)  
- [Datasets](https://huggingface.co/docs/datasets/)  
- [PyTorch](https://pytorch.org/)  
- Python 3.11+  

---

## ğŸ“‚ Project Structure
â”œâ”€â”€ gemma-3-270m.ipynb # Notebook for fine-tuning
â”œâ”€â”€ data/ # Dataset (Tiny Stories)
â”œâ”€â”€ outputs/ # Model checkpoints and logs
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Project documentation

---

## âš™ï¸ Setup

Clone the repository and install dependencies:

```bash
git clone https://github.com/yourusername/gemma-tinystories.git
cd gemma-tinystories
pip install -r requirements.txt


---

## âš™ï¸ Setup

Clone the repository and install dependencies:

```bash
git clone https://github.com/yourusername/gemma-tinystories.git
cd gemma-tinystories
pip install -r requirements.txt
```
ğŸ”® Future Work

Explore LoRA fine-tuning for parameter-efficient training.

Extend dataset to longer narrative texts.

Experiment with RLHF (Reinforcement Learning with Human Feedback).

